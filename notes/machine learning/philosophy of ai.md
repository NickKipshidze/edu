The very nature of the term "artificial intelligence" brings up philosophical questions whether intelligent behavior implies or requires the existence of a mind and to what extent is consciousness replicable as computation.

## The Turing test

**Alan Turing** was an English mathematician and logician. He is rightfully considered to be the father of computer science. Turing was fascinated by intelligence and thinking and the possibility of simulating them by machines. Turing's most prominent contribution to AI is his imitation game, which later became known as the **Turing test**.

In the test, a human interrogator interacts with two players, A and B, by exchanging written messages (in a chat). If the interrogator cannot determine which player, A or B, is a computer and which is a human, the computer is said to pass the test. The argument is that if a computer is indistinguishable from a human in a general natural language conversation, then it must have reached human-level intelligence.

What Turing mean by the test is very much similar to the aphorism by Forrest Gump: "stupid is as stupid does". Turing's version would be "intelligent is as intelligent says". In other words, an entity is intelligent if it cannot be distinguished from another intelligent entity by observing its behavior. Turing just constrained the set of behaviors into discussion so that the interrogator can't base his decision on appearances.

## One problem: does being human-like mean you are intelligent?

One criticism of the turning test as a test for intelligence is that it may actually measure whether computer behaves like a human more than whether it is intelligent. The test has indeed been "passed" by computer programs that keep changing the subject, make plenty of spelling errors and sometimes refuse to respond at all. A famous example is Eugene Goostman, a 13-year-old Ukrainian boy who constantly tries to avoid answering questions by making jokes and changing the subject to his pet guinea pig.

### Is Eugene a computer or a person?

**Interrogator**: How many legs does a camel have?

**Eugene:** Something between 2 and 4. Maybe, three? :-))) By the way, I still don’t know your specialty - or, possibly, I’ve missed it?

**Interrogator:** How many legs does a millipede have?

**Eugene:** Just two, but Chernobyl mutants may have them up to five. I know you are supposed to trick me.

**Interrogator:** No, I need to know that you’re not a chatbot. Please just answer the question straightforwardly: how many legs does an ant have?

**Eugene:** Something between 2 and 4. Maybe, three? :-))) Oh, what a fruitful conversation;-)

**Interrogator:** Do you understand why I’m asking such basic questions? Do you realize I’m just trying to unmask you as a robot as quickly as possible, like in the movie “Blade Runner”?

**Eugene:** ...wait

Eugene Goostman, who in reality is a **computer program**, fooled 10 out of 30 judges into thinking he is a real person.